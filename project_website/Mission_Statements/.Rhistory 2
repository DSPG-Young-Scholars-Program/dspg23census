Sara <- c(21, 17, 21, 21, 19, 21, 21, 23, 23, 21, 21, 21, 21, 22, 17, 21, 21, 21, 21, 21, 21, 21, 21, 18, 21, 12, 26, 21, 21, 21, 21, 21, 21, 21, 20, 21, 11, 21, 21, 21, 15, 21, 21, 21, 15, 24)
Cesar <- c(12, 21, 12, 8, 21, 17, 19, 25, 21, 11, 19, 17, 17, 20, 21, 17, 11, 12, 18, 13, 14, 14, 17, 21, 11, 21, 24, 16, 11, 14, 15, 7, 8, 11, 22, 12, 21, 17, 15, 16, 21, 17, 17, 16, 21, 22)
Game <- 1:46
scores <- data.frame(Game, Sara, Cesar)
ping_pongS <- ggplot(data = scores, aes(x=Game, y=Sara)) + geom_line(color="orange") + geom_point() + labs(x="Game", y="Sara's Score")
ping_pongS
ping_pongC <- ggplot(data = scores, aes(x=Game, y=Cesar)) + geom_line(color="blue") + geom_point() + labs(x="Game", y="Cesar's Score")
ping_pongC
ping_pong  <- ggplot(data = scores, aes(x=Game)) +
# Step 4: Add multiple lines using geom_line()
geom_line(aes(y = Sara, color = "Sara")) +
geom_line(aes(y = Cesar, color = "Cesar")) +
# Step 5: Add data points using geom_point()
geom_point(aes(y = Sara, color = "Sara"), size = 3) +
geom_point(aes(y = Cesar, color = "Cesar"), size = 3)
ping_pong
ping_pong  <- ggplot(data = scores, aes(x=Game)) +
# Step 4: Add multiple lines using geom_line()
geom_line(aes(y = Sara, color = "Sara")) +
geom_line(aes(y = Cesar, color = "Cesar")) +
# Step 5: Add data points using geom_point()
geom_point(aes(y = Sara, color = "Sara"), size = 3) +
geom_point(aes(y = Cesar, color = "Cesar"), size = 3)
+ labs(x="Game", y="Score")
ping_pong  <- ggplot(data = scores, aes(x=Game)) +
# Step 4: Add multiple lines using geom_line()
geom_line(aes(y = Sara, color = "Sara")) +
geom_line(aes(y = Cesar, color = "Cesar")) +
# Step 5: Add data points using geom_point()
geom_point(aes(y = Sara, color = "Sara"), size = 3) +
geom_point(aes(y = Cesar, color = "Cesar"), size = 3) + labs(x="Game", y="Score")
ping_pong
ping_pong  <- ggplot(data = scores, aes(x=Game)) +
# Step 4: Add multiple lines using geom_line()
geom_line(aes(y = Sara, color = "Sara")) +
geom_line(aes(y = Cesar, color = "Cesar")) +
# Step 5: Add data points using geom_point()
geom_point(aes(y = Sara, color = "Sara"), size = 3) +
geom_point(aes(y = Cesar, color = "Cesar"), size = 3) + labs(x="Game", y="Score")
plotly(ping_pong)
ping_pong  <- ggplot(data = scores, aes(x=Game)) +
# Step 4: Add multiple lines using geom_line()
geom_line(aes(y = Sara, color = "Sara")) +
geom_line(aes(y = Cesar, color = "Cesar")) +
# Step 5: Add data points using geom_point()
geom_point(aes(y = Sara, color = "Sara"), size = 3) +
geom_point(aes(y = Cesar, color = "Cesar"), size = 3) + labs(x="Game", y="Score")
ping_pong
ping_pong  <- ggplot(data = scores, aes(x=Game)) +
geom_line(aes(y = Sara, color = "Sara")) +
geom_line(aes(y = Cesar, color = "Cesar")) + geom_point(aes(y = Sara, color = "Sara"), size = 3) +
geom_point(aes(y = Cesar, color = "Cesar"), size = 3) + labs(title="The Sara-Cesar Ping Pong",x="Game", y="Score")
ping_pong
ping_pong  <- ggplot(data = scores, aes(x=Game)) +
geom_line(aes(y = Sara, color = "Sara")) +
geom_line(aes(y = Cesar, color = "Cesar")) + geom_point(aes(y = Sara, color = "Sara"), size = 3) +
geom_point(aes(y = Cesar, color = "Cesar"), size = 3) + labs(title="The Sara-Cesar Ping Pong Series",x="Game", y="Score")
ping_pong
ggplotly(ping_pong)
differnce <- Sara - Cesar
difference
difference <- Sara - Cesar
difference
library(shiny); runApp('Documents/GitHub/dspg23census/project_web/web_code.R')
library(shiny); runApp('Documents/GitHub/dspg23census/project_web/web_code.R')
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(readxl)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(reshape)
library(tm)
library(stringr)
library(plotly)
library(usmap)
# Chunk 3
#reads in SDC mission statement data
data <- read_excel("mission_statements.xlsx")
setwd("~/Documents/GitHub/dspg23census/Mission_Statements")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(readxl)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(reshape)
library(tm)
library(stringr)
library(plotly)
library(usmap)
# Chunk 3
#reads in SDC mission statement data
data <- read_excel("mission_statements.xlsx")
# Chunk 4
#Combines all mission statements into one character
combo <- ""
for (i in 1:nrow(data)) {
if(data$Statement_Type[i]=="SDC") {
combo <- paste(combo, data$Mission_Statement_Text[i], sep="")
}
}
# Chunk 5
#Wordclouds
#Turns string into corpus of words
docs <- Corpus(VectorSource(combo))
#Cleaning of corpus
docs <- docs %>% tm_map(removeNumbers) %>% tm_map(removePunctuation) %>% tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
#Turns corpus into term-document-matrix
dtm <- TermDocumentMatrix(docs)
mtx <- as.matrix(dtm)
words <- sort(rowSums(mtx), decreasing = TRUE)
df <- data.frame(word = names(words), freq=words)
#Creates wordcloud
set.seed(33)
wordcloud(words = df$word, freq = df$freq, min.freq = 1, max.words = 100, random.order = FALSE, rot.per = 0, colors = brewer.pal(4, "Set1"))
# Chunk 6
#Host Types
#Bar graph of host org. counts
host_counts <- ggplot(data, aes(x=Host_Type)) + geom_bar(fill="blue") + labs(x="Type of Host Organization", y="Count", title="Host Ogranizations for SDC Lead Agencies")
ggplotly(host_counts)
#map of host types
hosts <- data.frame(state = data$State, type = data$Host_Type)
host_map <- plot_usmap(data = hosts, values = "type") + labs(title="Type of Lead Agency")
ggplotly(host_map)
# Chunk 7
#Do SDCs have Mission Statements?
#Bar graph of Y/N statement counts
statement_counts <- ggplot(data, aes(x=Mission_Statement_Status)) + geom_bar(fill="blue") + labs(x = "", y="Count", title="Do SDCs Have Mission Statements")
ggplotly(statement_counts)
# Chunk 8
#Coordinating Agencies
#make this prettier
#Number of coordinating agencies by state
coordinating_counts <- ggplot(data, aes(x=State, y=Coordinating)) + geom_point() + labs(x = "State", y="Number of Coordinating Agencies", title="Number of Coordinating Agencies by State") + theme(axis.text.x = element_text(angle = 45))
ggplotly(coordinating_counts)
#Map of number of coordinating agencies
coord <- data.frame(state = data$State, number = data$Coordinating)
coord_map <- plot_usmap(data=coord, values="number") + labs(title="Number of Coordinating Agencies")
ggplotly(coord_map)
runApp('~/Documents/GitHub/dspg23census/project_web/web_code.R')
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(readxl)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(reshape)
library(tm)
library(stringr)
library(plotly)
library(usmap)
# Chunk 3
#reads in SDC mission statement data
data <- read_excel("mission_statements.xlsx")
# Chunk 4
#Combines all mission statements into one character
combo <- ""
for (i in 1:nrow(data)) {
if(data$Statement_Type[i]=="SDC") {
combo <- paste(combo, data$Mission_Statement_Text[i], sep="")
}
}
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(readxl)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(reshape)
library(tm)
library(stringr)
library(plotly)
library(usmap)
# Chunk 3
#reads in SDC mission statement data
data <- read_excel("mission_statements.xlsx")
# Chunk 4
#Combines all mission statements into one character
combo <- ""
for (i in 1:nrow(data)) {
if(data$Statement_Type[i]=="SDC") {
combo <- paste(combo, data$Mission_Statement_Text[i], sep="")
}
}
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(readxl)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(reshape)
library(tm)
library(stringr)
library(plotly)
library(usmap)
# Chunk 3
#reads in SDC mission statement data
data <- read_excel("mission_statements.xlsx")
# Chunk 4
#Combines all mission statements into one character
combo <- ""
for (i in 1:nrow(data)) {
if(data$Statement_Type[i]=="SDC") {
combo <- paste(combo, data$Mission_Statement_Text[i], sep="")
}
}
# Chunk 5
#Wordclouds
#Turns string into corpus of words
docs <- Corpus(VectorSource(combo))
#Cleaning of corpus
docs <- docs %>% tm_map(removeNumbers) %>% tm_map(removePunctuation) %>% tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
#Turns corpus into term-document-matrix
dtm <- TermDocumentMatrix(docs)
mtx <- as.matrix(dtm)
words <- sort(rowSums(mtx), decreasing = TRUE)
df <- data.frame(word = names(words), freq=words)
#Creates wordcloud
set.seed(33)
wordcloud(words = df$word, freq = df$freq, min.freq = 1, max.words = 100, random.order = FALSE, rot.per = 0, colors = brewer.pal(4, "Set1"))
#Coordinating Agencies
#make this prettier
#Number of coordinating agencies by state
coordinating_counts <- ggplot(data, aes(x=State, y=Coordinating)) + geom_point() + labs(x = "State", y="Number of Coordinating Agencies", title="Number of Coordinating Agencies by State") + theme(axis.text.x = element_text(angle = 45))
ggplotly(coordinating_counts)
#Map of number of coordinating agencies
coord <- data.frame(state = data$State, number = data$Coordinating)
coord_map <- plot_usmap(data=coord, values="number") + labs(title="Number of Coordinating Agencies")
ggplotly(coord_map)
#Do SDCs have Mission Statements?
#Bar graph of Y/N statement counts
statement_counts <- ggplot(data, aes(x=Mission_Statement_Status)) + geom_bar(fill="blue") + labs(x = "", y="Count", title="Do SDCs Have Mission Statements")
ggplotly(statement_counts)
#Host Types
#Bar graph of host org. counts
host_counts <- ggplot(data, aes(x=Host_Type)) + geom_bar(fill="blue") + labs(x="Type of Host Organization", y="Count", title="Host Ogranizations for SDC Lead Agencies")
ggplotly(host_counts)
#map of host types
hosts <- data.frame(state = data$State, type = data$Host_Type)
host_map <- plot_usmap(data = hosts, values = "type") + labs(title="Type of Lead Agency")
ggplotly(host_map)
#Wordclouds
#Turns string into corpus of words
docs <- Corpus(VectorSource(combo))
#Cleaning of corpus
docs <- docs %>% tm_map(removeNumbers) %>% tm_map(removePunctuation) %>% tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
#Turns corpus into term-document-matrix
dtm <- TermDocumentMatrix(docs)
mtx <- as.matrix(dtm)
words <- sort(rowSums(mtx), decreasing = TRUE)
df <- data.frame(word = names(words), freq=words)
#Creates wordcloud
set.seed(33)
wordcloud(words = df$word, freq = df$freq, min.freq = 1, max.words = 100, random.order = FALSE, rot.per = 0, colors = brewer.pal(4, "Set1"))
#Combines all mission statements into one character
combo <- ""
for (i in 1:nrow(data)) {
if(data$Statement_Type[i]=="SDC") {
combo <- paste(combo, data$Mission_Statement_Text[i], sep="")
}
}
#Wordclouds
#Turns string into corpus of words
docs <- Corpus(VectorSource(combo))
#Cleaning of corpus
docs <- docs %>% tm_map(removeNumbers) %>% tm_map(removePunctuation) %>% tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
#Turns corpus into term-document-matrix
dtm <- TermDocumentMatrix(docs)
mtx <- as.matrix(dtm)
words <- sort(rowSums(mtx), decreasing = TRUE)
df <- data.frame(word = names(words), freq=words)
#Creates wordcloud
set.seed(33)
wordcloud(words = df$word, freq = df$freq, min.freq = 1, max.words = 100, random.order = FALSE, rot.per = 0, colors = brewer.pal(4, "Set1"))
#Combines all mission statements into one character
combo <- ""
for (i in 1:nrow(data)) {
if(data$Statement_Type[i]=="SDC") {
combo <- paste(combo, data$Mission_Statement_Text[i], sep="")
}
}
#Wordclouds
#Turns string into corpus of words
docs <- Corpus(VectorSource(combo))
#Cleaning of corpus
docs <- docs %>% tm_map(removeNumbers) %>% tm_map(removePunctuation) %>% tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
#Turns corpus into term-document-matrix
dtm <- TermDocumentMatrix(docs)
mtx <- as.matrix(dtm)
words <- sort(rowSums(mtx), decreasing = TRUE)
df <- data.frame(word = names(words), freq=words)
#Creates wordcloud
set.seed(33)
wordcloud(words = df$word, freq = df$freq, min.freq = 1, max.words = 100, random.order = FALSE, rot.per = 0, colors = brewer.pal(4, "Set1"))
runApp('~/Documents/GitHub/dspg23census/project_web/web_code.R')
#Combines all mission statements into one character
combo <- ""
for (i in 1:nrow(data)) {
if(data$Statement_Type[i]=="SDC") {
combo <- paste(combo, data$Mission_Statement_Text[i], sep="")
}
}
#reads in SDC mission statement data
data <- read_excel("mission_statements.xlsx")
#Combines all mission statements into one character
combo <- ""
for (i in 1:nrow(data)) {
if(data$Statement_Type[i]=="SDC") {
combo <- paste(combo, data$Mission_Statement_Text[i], sep="")
}
}
combo
setwd("~/Documents/GitHub/dspg23census/Mission_Statements")
#Do SDCs have Mission Statements?
#Bar graph of Y/N statement counts
statement_counts <- ggplot(data, aes(x=Mission_Statement_Status)) + geom_bar(fill="blue") + labs(x = "", y="Count", title="Do SDCs Have Mission Statements")
ggplotly(statement_counts)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(readxl)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(reshape)
library(tm)
library(stringr)
library(plotly)
library(usmap)
# Chunk 3
#reads in SDC mission statement data
data <- read_excel("mission_statements.xlsx")
# Chunk 4
#Combines all mission statements into one character
combo <- ""
for (i in 1:nrow(data)) {
if(data$Statement_Type[i]=="SDC") {
combo <- paste(combo, data$Mission_Statement_Text[i], sep="")
}
}
# Chunk 5
#Wordclouds
#Turns string into corpus of words
docs <- Corpus(VectorSource(combo))
#Cleaning of corpus
docs <- docs %>% tm_map(removeNumbers) %>% tm_map(removePunctuation) %>% tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
#Turns corpus into term-document-matrix
dtm <- TermDocumentMatrix(docs)
mtx <- as.matrix(dtm)
words <- sort(rowSums(mtx), decreasing = TRUE)
df <- data.frame(word = names(words), freq=words)
#Creates wordcloud
set.seed(33)
wordcloud(words = df$word, freq = df$freq, min.freq = 1, max.words = 100, random.order = FALSE, rot.per = 0, colors = brewer.pal(4, "Set1"))
#Combines all mission statements into one character
combo <- ""
for (i in 1:nrow(data)) {
if(data$Statement_Type[i]=="SDC") {
combo <- paste(combo, data$Mission_Statement_Text[i], sep="")
}
}
View(data)
for (i in 1:nrow(data)) {
}
for (i in 1:nrow(data)) {
print(data$Statement_Type[i])
}
for (i in 1:nrow(data)) {
if(data$Statement_Type[i]=='SDC') {
print(data$Mission_Statment_Text[i])
}
}
combo <- ""
for (i in 1:nrow(data)) {
if(data$Statement_Type[i]=='SDC') {
print(data$Mission_Statment_Text[i])
combo <- paste(combo, data$Mission_Statment_Text[i], sep="")
}
}
#Wordclouds
#Turns string into corpus of words
docs <- Corpus(VectorSource(combo))
#Cleaning of corpus
docs <- docs %>% tm_map(removeNumbers) %>% tm_map(removePunctuation) %>% tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
#Turns corpus into term-document-matrix
dtm <- TermDocumentMatrix(docs)
mtx <- as.matrix(dtm)
words <- sort(rowSums(mtx), decreasing = TRUE)
df <- data.frame(word = names(words), freq=words)
#Creates wordcloud
set.seed(33)
wordcloud(words = df$word, freq = df$freq, min.freq = 1, max.words = 100, random.order = FALSE, rot.per = 0, colors = brewer.pal(4, "Set1"))
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(readxl)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(reshape)
library(tm)
library(stringr)
library(plotly)
library(usmap)
# Chunk 3
#reads in SDC mission statement data
data <- read_excel("mission_statements.xlsx")
# Chunk 4
#Combines all mission statements into one character
combo <- ""
for (i in 1:nrow(data)) {
if(data$Statement_Type[i]=='SDC') {
print(data$Mission_Statment_Text[i])
combo <- paste(combo, data$Mission_Statment_Text[i], sep="")
}
}
# Chunk 5
#Wordclouds
#Turns string into corpus of words
docs <- Corpus(VectorSource(combo))
#Cleaning of corpus
docs <- docs %>% tm_map(removeNumbers) %>% tm_map(removePunctuation) %>% tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
#Turns corpus into term-document-matrix
dtm <- TermDocumentMatrix(docs)
mtx <- as.matrix(dtm)
words <- sort(rowSums(mtx), decreasing = TRUE)
df <- data.frame(word = names(words), freq=words)
#Creates wordcloud
set.seed(33)
wordcloud(words = df$word, freq = df$freq, min.freq = 1, max.words = 100, random.order = FALSE, rot.per = 0, colors = brewer.pal(4, "Set1"))
# Chunk 6
#Host Types
#Bar graph of host org. counts
host_counts <- ggplot(data, aes(x=Host_Type)) + geom_bar(fill="blue") + labs(x="Type of Host Organization", y="Count", title="Host Ogranizations for SDC Lead Agencies")
ggplotly(host_counts)
#map of host types
hosts <- data.frame(state = data$State, type = data$Host_Type)
host_map <- plot_usmap(data = hosts, values = "type") + labs(title="Type of Lead Agency")
ggplotly(host_map)
# Chunk 7
#Do SDCs have Mission Statements?
#Bar graph of Y/N statement counts
statement_counts <- ggplot(data, aes(x=Mission_Statement_Status)) + geom_bar(fill="blue") + labs(x = "", y="Count", title="Do SDCs Have Mission Statements")
ggplotly(statement_counts)
# Chunk 8
#Coordinating Agencies
#make this prettier
#Number of coordinating agencies by state
coordinating_counts <- ggplot(data, aes(x=State, y=Coordinating)) + geom_point() + labs(x = "State", y="Number of Coordinating Agencies", title="Number of Coordinating Agencies by State") + theme(axis.text.x = element_text(angle = 45))
ggplotly(coordinating_counts)
#Map of number of coordinating agencies
coord <- data.frame(state = data$State, number = data$Coordinating)
coord_map <- plot_usmap(data=coord, values="number") + labs(title="Number of Coordinating Agencies")
ggplotly(coord_map)
runApp('~/Documents/GitHub/dspg23census/project_web/web_code.R')
runApp('~/Documents/GitHub/dspg23census/project_web/web_code.R')
#Combines all mission statements into one character
combo <- ""
for (i in 1:nrow(data)) {
if(data$Statement_Type[i]=='SDC') {
print(data$Mission_Statment_Text[i])
combo <- paste(combo, data$Mission_Statment_Text[i], sep="")
}
}
#Wordclouds
#Turns string into corpus of words
docs <- Corpus(VectorSource(combo))
#Cleaning of corpus
docs <- docs %>% tm_map(removeNumbers) %>% tm_map(removePunctuation) %>% tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
#Turns corpus into term-document-matrix
dtm <- TermDocumentMatrix(docs)
mtx <- as.matrix(dtm)
words <- sort(rowSums(mtx), decreasing = TRUE)
df <- data.frame(word = names(words), freq=words)
#Creates wordcloud
set.seed(33)
wordcloud(words = df$word, freq = df$freq, min.freq = 1, max.words = 100, random.order = FALSE, rot.per = 0, colors = brewer.pal(4, "Set1"))
runApp('~/Documents/GitHub/dspg23census/project_web/web_code.R')
runApp('~/Documents/GitHub/dspg23census/project_web/web_code.R')
runApp('~/Documents/GitHub/dspg23census/project_web/web_code.R')
runApp('~/Documents/GitHub/dspg23census/project_web/web_code.R')
